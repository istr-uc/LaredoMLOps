# LaredocMind - Backend

## Description
LaredocMind backend exposes a REST API where users can send questions and receive answers generated by the chatbot. The backend is built using LangGraph, enabling advanced conversational flows and context management. It supports document ingestion (local and web), embeddings, and evaluation, but its main purpose is to provide intelligent, context-aware responses to user queries through the chatbot interface.

## Installation and Quick Start

**Important:** Before starting the installation, create a `.env` file in the `backend` folder and add your required API keys and environment variables using `.env.example`. Example:

```
GOOGLE_API_KEY=your_openai_key_here
...
```

You can set up and run the backend using either the quick script option or by following the manual steps.

### Quick Option (Recommended)

1. Open a terminal in the `backend` folder.
2. Run the following script to install all dependencies and prepare the environment:
   ```sh
   setup_backend.bat
   ```
3. To start the backend server once instaled, run:
   ```sh
   run_backend.bat
   ```

### Manual Option

1. **Create and activate a virtual environment:**
   ```sh
   python -m venv .venv
   .venv\Scripts\activate
   ```

2. **Install Poetry (if not already installed):**
   ```sh
   pip install poetry
   ```

3. **Install project dependencies:**
   ```sh
   poetry install
   ```

4. **Run the backend server:**
   ```sh
   .\run_backend.bat
   ```

5. **Verify the backend is running:**
   Open your browser and go to [http://localhost:20000/hello](http://localhost:20000/hello). If everything is working, you will see a greeting message. Change 20000 to the port you selected. (20000 by default)

## Project Structure

```
backend/
├── docs/                  # Documentation: user guides, technical docs, reports
├── src/                   # Main source code
│   ├── api/               # REST API endpoints and chatbot service
│   ├── chatbot/           # Chatbot logic, initialization, and state management
│   ├── config/            # Configuration files (parameters, URLs, settings)
│   ├── utils/             # Utilities for document loading, embeddings, logging, etc.
│   ├── evaluator/         # Evaluation metrics and example creation
│   └── wsgi.py            # WSGI entry point for backend server
├── tests/                 # Unit and integration tests
├── database/              # Database files and storage (created on start)
├── README.md              # Project documentation (this file)
├── pyproject.toml         # Project dependencies and build config (Poetry)
└── init.bat               # Script to set PYTHONPATH on Windows
```

## Detailed Folder and File Descriptions

### `docs/`
Contains user guides, technical documentation, and reference material for Laredo.

---

### `src/`
Main source code, organized by responsibility:

#### `api/`
Implements the REST API endpoints and chatbot service:
- `api.py`: Main FastAPI routes for question/answer and model interaction.
- `chatbot_service.py`: Backend logic for chatbot-related API endpoints.
- `test_sin_stream.html`: (Test/demo) HTML for API streaming.

#### `chatbot/`
Core chatbot logic and orchestration:
- `chat_initializer.py`: Initializes chatbot components.
- `core_initializer.py`: Sets up models, embeddings, and document management.
- `graph_initializer.py`: Manages the chatbot's state graph and conversational flow (using LangGraph).
- `main.py`: Entry point for running the chatbot in standalone mode (consoe).

#### `config/`
Configuration files for parameters, URLs, and settings:
- `config_chatbot.py`: Prompt templates and chatbot-specific settings.
- `config_init.py`: Document splitting, LLM, and embedding configurations.
- `config_url.py`: URLs for web-based documents.

#### `evaluator/`
Evaluation and example generation:
- `evaluators.py`: Implements BLEU, ROUGE-L, and other metrics for chatbot/model evaluation.
- `example_creation.py`: Example prompts and templates for testing and evaluation.

#### `utils/`
Utility modules for document and model management:
- `directory_loader.py`: Loads Markdown documents from a directory.
- `document_manager.py`: Loads, splits, and organizes local and web documents.
- `embedding_manager.py`: Manages embeddings for retrieval and similarity search.
- `gemini_model_manager.py`: Integrates Gemini language model and embeddings.
- `key_manager.py`: Reads, validates, and stores API keys.
- `logger_manager.py`: Logging system setup using Loguru.
- `ollama_model_manager.py`: Integrates Ollama models.
- `web_loader.py`: Fetches and processes web pages as Markdown documents.

- `wsgi.py`: WSGI entry point for backend server (for deployment).

---

### `tests/`
Unit and integration tests for validating backend functionality:
- `document_manager_test.py`: Tests for document loading and splitting.
- `embedding_manager_test.py`: Tests for embedding management.
- `gemini_model_manager_test.py`: Tests for Gemini model integration.
- `key_manager_test.py`: Tests for API key management.
- `ollama_model_manager_test.py`: Tests for Ollama model integration.

---

### `database/`
Database files and storage (e.g., Chroma vector DB) used for embeddings and persistent data.

---

### `pyproject.toml`
Project dependencies and build configuration (Poetry-based).

---

### `README.md`
Project documentation (this file).

## Troubleshooting

### Common Issues
- **PYTHONPATH Issues**: If you encounter import errors, run `init.bat` to set the correct PYTHONPATH for Windows.
- **Dependency Problems**: Ensure all dependencies are installed with `poetry install` and that your virtual environment is activated.
- **Database Errors**: Confirm that the `database/` folder is writable and that the Chroma database files are not corrupted. If the app behaves unexpectedly, try deleting the contents of the `database/` folder before restarting the backend.
- **API Not Responding**: Make sure the backend is running (`python src/wsgi.py`) and check for errors in the terminal.
- **Port Conflicts**: If the server fails to start, verify that the default port is not in use by another process.

### Verifying the Backend
- To verify the backend is running correctly, open your browser and go to `http://localhost:YOUR_PORT/hello`. If everything is working, you should see a hello message.

### Debugging
- You can enable debug mode in the logger to display more detailed information about what is happening in the backend. Check the `logger_manager.py` file in `src/utils/` for configuration options, and set the logger to debug level if you need more verbose output.

## License

This project is licensed under the MIT License. You are free to use, modify, and distribute this software, provided that the original copyright and license notice are included.

See the `LICENSE` file for the full license text.
